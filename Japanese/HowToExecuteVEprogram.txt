VEOS:VEプログラムの実行方法
Date:2020/12

この文書は VEOS version 2.6.2 以降についての情報を記載しています。


はじめに、対象のVH(VEが接続されるLinux/x86マシン)にログインしてください。

- 対象のVHで何ノードのVEを使用でき、それぞれCPUコアをいくつ使用できるか

  $ unset VE_NODE_NUMBER
  $ /opt/nec/ve/bin/uptime | grep Node
  VE Node: 1
  VE Node: 0
           ^この番号はVEノード番号です。

  この場合、2ノード(#0,1)使用可能です。

  $ /opt/nec/ve/bin/nproc
  VE Node: 1
  8
  VE Node: 0
  8

  この場合、それぞれのVEノードで8コアを使用可能です。

  (注意) 実行するVEプログラムのプロセス/スレッド数がVEのCPUコア数以下の時に
         VE性能を最大限に引き出せます。これはVEプログラム実行中にコンテキスト
         スイッチが発生しないからです。


- VEプログラムの作り方

  $ vi hello.c
  $ /opt/nec/ve/bin/ncc hello.c -o hello


- VEOS 動作モードの確認

  VEOS は Normal モードと NUMA モード、２つの動作モードをサポートしています。
  /opt/nec/ve/bin/venumainfo コマンドでモードをチェックすることができます。

   $ /opt/nec/ve/bin/venumainfo

  Normal モードの場合、venumainfo は "available: 1 nodes(0)" を表示し、
  VE の情報を "node 0" として表示します。

  NUMA モードの場合、venumainfo は "available: 2 nodes(0-1)" を表示し、
  "node 0" (NUMA ノード 0) と "node 1" (NUMA ノード 1) の情報を表示します。


- VEプログラムの実行方法

  VEノード#0でプログラムを実行する場合:

   $ /opt/nec/ve/bin/ve_exec -N 0 ./hello

  VEノード#1でプログラムを実行する場合:

   $ /opt/nec/ve/bin/ve_exec -N 1 ./hello

  あるいは、VEノード番号を意味する環境変数を設定すれば、-Nオプションを指定する
  必要ありません。例えば:

   $ export VE_NODE_NUMBER=1
   $ /opt/nec/ve/bin/ve_exec ./hello

  binfmt の設定がインストール時に行われているため、VEプログラムをve_execなしに
  実行することも可能です。複数のVEが搭載されている場合、VEプログラムを実行する
  VEノードを環境変数(VE_NODE_NUMBER)で指定します。

   $ export VE_NODE_NUMBER=1
   $ ./hello

  動的リンカが、動的リンクライブラリ(共有ライブラリ)を検索するパスを変更したい
  場合、VE の環境変数 VE_LD_LIBRARY_PATH を事前に設定してください。 
  /path/to/usr/lib を検索させたい場合は、以下の様に指定します。

   $ export VE_LD_LIBRARY_PATH=/path/to/usr/lib
   $ /opt/nec/ve/bin/ve_exec ./hello

  その他のオプション・環境変数については、「ve_execオプション」
  「環境変数」の節を参照してください。


- VEプログラムの実行方法 (NUMA モード)

  VEOS が NUMA モードで動作している場合、VE を NUMA の様に利用することが
  できます。

  プログラムを NUMA オプションなしに実行すると、VEOS は負荷の低い NUMA 
  ノードにそのプログラムのプロセスを生成します。プログラムがメモリ割り当てを
  要求した場合は、プログラムが動作しているローカル NUMA ノードに属するメモリ
  (ローカルメモリ) が最初に割り当てられます。ローカルメモリが一杯の場合、
  反対側の NUMA ノードに属するメモリ (リモートメモリ) が割り当てられます。

   $ /opt/nec/ve/bin/ve_exec ./hello

  使用する NUMA ノードやメモリポリシを指定するオプションを使う事ができます。

   $ /opt/nec/ve/bin/ve_exec --cpunodebind=0 --localmembind ./hello

  また、オプション指定のために NUMA 用の環境変数 VE_NUMA_OPT も利用できます。

   $ export VE_NUMA_OPT="--cpunodebind=0 --localmembind"
   $ /opt/nec/ve/bin/ve_exec ./hello

  (注意)
  デフォルトでは、VEOS はまずローカルメモリを割り当て、もしローカルメモリが
  一杯の場合はリモートメモリを割り当てます。VEOS はこのポリシを MPOL_DEFAULT
  と定義します。'--localmembind' が指定された場合は、VEOS はローカルメモリ
  のみを割り当てます。VEOS はこのポリシを MPOL_BIND と定義します。

  オプション・環境変数の詳細は、「ve_execオプション」「環境変数」の節を
  参照してください。


- 既定のライブラリ検索パスの追加方法

  規定値として検索パスを追加する場合は、"/etc/opt/nec/ve/ld.so.conf.d"ディレク
  トリに設定ファイルを追加した後、下記コマンドを実行してください。

   $ sudo /opt/nec/ve/glibc/sbin/ldconfig

  設定ファイルは末尾が".conf"の任意のファイル名とし、検索パスを記入します。


- 高速I/Oを有効にする方法

  高速I/Oは、VEとVH間で効率的にデータを転送することで、I/O性能を向上す
  るための機能です。

  以下のread/write系のシステムコールのスループットとレイテンシが改善し
  ます。
      read     write
      pread    pwrite
      readv    writev
      preadv   pwritev

  システム管理者は、「SX-Aurora TSUBASA インストールガイド」の指示に従
  い、カーネルパラメータ"vm.nr_hugepages"を使用して、高速I/O用に Huge
  Pages を予約する必要があります。

  デフォルトサイズのHuge Pagesを使用して高速I/Oを有効にするためには、
  環境変数 VE_ACC_IO を 1 に設定してください。

   $ export VE_ACC_IO=1
   $ ./hello

  次の点に注意をお願いします。

    * 高速I/O有効時、デフォルトで、1つの VE プロセスあたり、32 の Huge
      Pages (64MB Huge Pages メモリ) を使います。
    * 高速I/Oは、8MB単位でデータを転送します。そのため、サイズが8MBを超
　　  える場合、read/write系システムコールはアトミックではなくなります。


- VEプロセスの資源制限方法
  環境変数VE_LIMIT_OPTを設定して、VEプロセスの資源制限を行ってください。

   $ export VE_LIMIT_OPT="-c 10240 --softm 1234 --hardm 2345 -t 10"

  環境変数VE_LIMIT_OPTによってサポートされるリソースは以下の通りです。
    -v : virtual memory     RLIMIT_AS
    -c : core file size     RLIMIT_CORE
    -t : cpu time           RLIMIT_CPU
    -d : data seg size      RLIMIT_DATA
    -m : max memory size    RLIMIT_RSS
    -i : pending signals    RLIMIT_SIGPENDING
    -s : stack size         RLIMIT_STACK

  上記のオプションによりVEプロセスに対しソフトリミットとハードリミットの
  両方で制限をかけることが出来ます。以下のロングオプションを
  環境変数VE_LIMIT_OPTに指定することで、各資源に対しソフトリミットと
  ハードリミットを別々に設定することもできます。

    --softv: RLIMIT_AS soft limit         --hardv: RLIMIT_AS hard limit
    --softc: RLIMIT_CORE soft limit       --hardc: RLIMIT_CORE hard limit
    --softt: RLIMIT_CPU soft limit        --hardt: RLIMIT_CPU hard limit
    --softd: RLIMIT_DATA soft limit       --hardd: RLIMIT_DATA hard limit
    --softm: RLIMIT_RSS soft limit        --hardm: RLIMIT_RSS hard limit
    --softi: RLIMIT_SIGPENDING soft limit --hardi: RLIMIT_SIGPENDING hard limit
    --softs: RLIMIT_STACK soft limit      --hards: RLIMIT_STACK hard limit

  幾つかの上記項目（ソフトリミットとハードリミットのいずれか、もしくは両方）
  が環境変数によって設定されていない場合、制限は’ulimit’の値が引き継がれます。

  VE_LIMIT_OPTによってサポートされない資源制限は、VHのulimitから引き継がれます。
  もしスタックのサイズがVE_STACK_LIMITとVE_LIMIT_OPTの両方によって
  定義されていたら、VE_LIMIT_OPTの'-s'によって指定された値が優先され、
  VEプロセスに適用されます。

  これらの資源制限はVEプロセスにのみ適用可能であり、対応する代理プロセスの
  制限はVHのulimitから引き継がれます。


- VEプロセスのリソース制限を確認する方法
  ve_execのコマンドライン引数として"--show-limit"を指定すれば、
  アウトプットの3列目と4列目にそれぞれVE_LIMIT_OPTがサポートしている
  全ての資源に対して適用されているソフトリミットとハードリミットが表示されます。

   $ /opt/nec/ve/veos/bin/ve_exec --show-limit	
    core file size     (blocks, -c)     10240	     10240
    data seg size      (kbytes, -d)     unlimited    unlimited
    pending signals    (-i)             79349        79349
    max memory size    (kbytes, -m)     1234         2345
    stack size         (kbytes, -s)     unlimited    unlimited
    cpu time           (seconds, -t)    10           10
    virtual memory     (kbytes, -v)     unlimited    unlimited


- ve_exec オプション

  ve_exec コマンドは次のオプションを受け付けます。

    -V, --version                 バージョン情報表示
    -h, --help                    ヘルプ表示
    -N node, --node=<node>        実行 VE ノード指定
    -c core, --core=<core>        VEプログラムをどの VE コアで動かすかを
                                  コア番号で指定
                                  '-c' と '--cpunodebind' の両方を同時に
                                  指定することは不可
    --                            ve_exec オプションの終了 (VEバイナリ名が
                                  '-' で始まる場合に必要)
    --show-limit                  環境変数VE_LIMIT_OPTによってサポートされる、
                                  VEプロセスの資源に対して適用されている
                                  ソフトリミットとハードリミットを表示する

  NUMA mode のみ:
    --cpunodebind=<NUMA node ID>  VE プログラムを実行する NUMA ノード番号
                                  <NUMA node ID> を指定する
    --localmembind                ローカルメモリのみ割り当てる (MPOL_BIND)


- 環境変数

  以下の環境変数によって、プログラム実行の制御が可能です。

  * VE_NODE_NUMBER
    プログラムが実行される VEノード番号を指定します。
    VE_NODE_NUMBER を設定せず、ve_exec コマンドの -N オプションも指定せず
    に、VEプログラムを実行した場合、VEプログラムは VEノード#0で実行されます。

  * VE_LD_LIBRARY_PATH
    プログラム実行時に検索するライブラリパスを指定します。VE_LD_LIBRARY_PATH
    には、コロンで区切った複数のディレクトリを指定できます。

  * VE_LD_PRELOAD
    この環境変数は動的リンカにプリロードする共有ライブラリのパスを設定します。
    実行ファイルにロードされるどの共有ライブラリよりも先に、ユーザが指定する
    ライブラリをロードする事が可能です。

  * VE_ACC_IO
    この環境変数を 1 に設定すると、高速I/Oが有効になり、64MB の Huge Pages
    メモリを使用します。64MB はデフォルト値です。
    この環境変数を 2 に設定すると、高速I/Oが有効になり、(8MB * VEのコア数) の
    Huge Pages メモリを使用します。
    
    詳細は、この文書の「高速I/Oを有効にする方法」を参照してください。

  * VE_ATOMIC_IO
    この環境変数を1に設定すると、アトミックI/Oが有効になります。VEプログラムが
    read/write系システムコールやsend/recv系システムコールを呼び出すと、VH側で
    バッファが確保されます。アトミックI/Oが有効の場合、このバッファのサイズは、
    要求されたサイズと一致し、最大で2GBとなります。

    アトミックI/Oは以下のシステムコールに影響があります。

      read     write
      pread    pwrite
      readv    writev
      preadv   pwritev
      send     recv
      sendto   recvfrom

    もし、アトミックI/Oが無効の場合、バッファサイズは64MB固定です。要求されたサ
    イズが64MBを超える場合、64MBごとにデータが転送されます。この場合、
    read/write系システムコールやsend/recv系のシステムコールは、アトミックではな
    くなります。

  * VE_NUMA_OPT
    これは NUMA オプション "--cpunodebind" と "--localmembind" を指定します。
    VE_NUMA_OPT とコマンドライン引き数の両方で NUMA オプションが指定されている
    場合、VEOS はコマンドライン引き数で指定された値を使用します。

  * VE_LIMIT_OPT
    この環境変数はVEプロセスの資源制限のために用いられます。
    ハードリミット、ソフトリミットの両方を設定可能です。
    詳しくは"VEプロセスの資源制限方法"を参照してください。


- VEOSコマンドの実行方法

  例えば、VEノード#0に対するpsコマンドを実行する場合:

   $ export VE_NODE_NUMBER=0
   $ /opt/nec/ve/bin/ps

  VEノード#1に対するpsコマンドを実行する場合:

   $ export VE_NODE_NUMBER=1
   $ /opt/nec/ve/bin/ps

  VEOSは/opt/nec/ve/bin/配下にある以下のコマンドをサポートします:
  
   aclocal
   aclocal-1.13
   autoconf
   autoheader
   autom4te
   automake
   automake-1.13
   autoreconf
   autoscan
   autoupdate
   free
   gdb
   ifnames
   iostat
   ipcs
   ipcrm
   libtool
   libtoolize
   lscpu
   lslocks
   mpstat
   pidstat
   pmap
   prlimit
   prtstat
   ps
   sadf
   sar
   strace
   strace-log-merge
   taskset
   time
   tload
   top
   uptime
   ve-libc-check
   ve_exec
   ve_validate_binary
   venumainfo
   veswap
   vmstat
   w

  glibcは以下のコマンドをサポートします:

   /opt/nec/ve/glibc/sbin/ldconfig
   /opt/nec/ve/glibc/sbin/ldd


- VEプログラムのデバッグ方法

  GDBを使用可能です:
 
   $ export VE_NODE_NUMBER=0
   $ /opt/nec/ve/bin/gdb ./hello
   (gdb) run


- 実行ファイルや共有ライブラリの検査

  実行ファイルや共有ライブラリをロードして実行するためには、テキストセクション
  とデータセクションの間に1024バイト以上の隙間が必要です。隙間が1024バイト未満
  の場合は、ロードに失敗します。

  この隙間が1024バイト以上であることを、次のコマンドを実行して検査します。

    $ /opt/nec/ve/bin/ve_validate_binary

  オプションを指定しなければ、このコマンドはカレントディレクトリの実行ファイル
  と共有ライブラリを検索します。次のオプションが利用可能です。

    -f,	--file       検査するファイルを指定します。
    -d, --directory  実行ファイルや共有ライブラリを検索するディレクトリを指定し
                     ます。

  検査した全ての実行ファイルと共有ライブラリの隙間が1024バイト以上の場合は、
　このコマンドは次のメッセージを表示します。

    ***ALL VE BINARY/SHARED LIBRARIES ARE VALIDATED SUCCESSFULLY!!***

  ある実行ファイルまたは共有ライブラリの隙間が1024バイト未満の場合は、このコ
  マンドは次のメッセージを表示します。

    DATA/TEXT gap is less

  このメッセージが表示された場合は、実行ファイルまたは共有ライブラリを
  再リンクしてください。


- ビルドに利用したCライブラリの見分け方

  glibcを用いてコンパイルされたバイナリは、musl-libcを用いてコンパイルされたバ
  イナリと互換性がありません。バイナリにリンクされたCライブラリを区別したい場合
  には、以下のように"ve-libc-check"スクリプトを実行して下さい。このスクリプト
  は、全てのVEバイナリ("a.out", ".o", ".a", ".so")に対して利用することが可能
  です。

    $ /opt/nec/ve/bin/ve-libc-check ./a.out
    This is compiled with musl-libc: /home/userxxx/a.out

  上記のようなメッセージが表示される場合、"a.out"はmusl-libcを用いてビルドされ
  ています。何もメッセージが表示されない場合はmusl-libcを用いていません。

  (注意)
  * musl-libcは2019年3月末に廃止されました。SX-Aurora TSUBASA ソフトウェアは、
    今後 musl-libc をサポートしません。
  * ".s"ファイルから生成されたオブジェクトファイルを"ve-libc-check"で確認するこ
    とはできません。".s"ファイルを用いている場合には、musl-libcでコンパイルした
    バイナリとglibcでコンパイルしたバイナリを混在させないよう、ご注意をお願いい
    たします。
  * glibcでコンパイル・リンクしたVEプログラムが、musl-libcでビルドしたライブラ
    リを動的にリンクあるいはロードする場合には、"ve-libc-check"で確認することは
    できません。ご利用のライブラリをglibcを用いて再作成して頂くようお願いいたし
    ます。


- VEOSの問題発生時の情報採取

  解析には以下の情報が必要です。
    1. RPM パッケージとカーネルのバージョン情報
       以下のコマンドを実行してバージョン情報をファイルに保存して採取し
       てください。

        $ rpm -qa --qf '%{VENDOR} %{NAME}-%{VERSION}-%{RELEASE}.%{ARCH}\n' \
           | grep NEC > nec-version.txt
        $ uname -r > knl-version.txt

    2. ログファイル
       以下のログファイルを採取してください。

         /var/log/messages*
         /var/opt/nec/ve/veos/*.log.*
         /var/opt/nec/ve/log/sa/saDD_* (DD は問題が発生した日)
         /var/opt/nec/ve/veos/core.* (存在する場合)
         /var/lib/systemd/coredump/core.veos.* (存在する場合)
         /var/lib/systemd/coredump/core.ived.* (存在する場合)
         /var/lib/systemd/coredump/core.vemmd.* (存在する場合)

    3. プロセスアカウティングファイル
       プロセスアカウンティングが有効な場合、問題が発生した日と、その翌日の
       プロセスアカウンティングファイルを採取してください。
       プロセスアカウンティングファイルのパスは以下の通りです。

         /var/opt/nec/ve/account/pacct_?
             最新のファイル
         /var/opt/nec/ve/account/pacct_?-YYYYMMDD
             YYYYMMDD が示す年月日にローテーションされたファイル
         /var/opt/nec/ve/account/pacct_?-YYYYMMDD.gz
             YYYYMMDD が示す年月日にローテーションされ、圧縮されたファイル

       プロセスアカウンティングファイルのローテーションが3時ごろに行わ
       れるため、プロセスの情報が翌日のファイルに記録される可能性がある
       ことに注意してください。

  もし、VEプログラムがフリーズするような問題の場合は、次の情報も必要です。
  情報を採取するためには、gdb パッケージがインストールされている必要が
  あります。

    4. VEOS と ve_exec のスタックトレース
       root権限で次のコマンドを実行して、VEOS と ve_exec のスタックトレース
       を取得してください。生成された pstack-* ファイルを採取してください。

        # for i in `seq 3`; do \
          pgrep veos | while read pid; do pstack $pid > pstack-veos.$pid.$i; done; \
          pgrep ve_exec | while read pid; do pstack $pid > pstack-ve_exec.$pid.$i; done; \
          sleep 10; done


- VEOS のデバッグログの採取方法
  再現可能なVEOSの問題の場合、以下の情報も解析に役立ちます。

  情報採取のレベルをデバッグに変更願います。

   $ sudo cp /etc/opt/nec/ve/veos/log4crc /etc/opt/nec/ve/veos/log4crc.org
   $ sudo sed -i -e 's/INFO/DEBUG/g' -e 's/CRIT/DEBUG/g' -e 's/layout="ve"/layout="ve_debug"/g' /etc/opt/nec/ve/veos/log4crc

  設定を反映するために、VEOSをリブートしてください。

   $ sudo systemctl restart 've-os-launcher@*'

  情報採取のために、以下の環境変数を設定願います。

   $ export LOG4C_RCPATH=/etc/opt/nec/ve/veos

  次に、問題を再現させてください。この時、ve_execのログファイルがカレントディ
  レクトリに作成されます。

   ./ve_exec.log.*

  なお、以下の情報も忘れずにお願いします。

   /var/log/messages*
   /var/opt/nec/ve/veos/*.log.*
   /var/opt/nec/ve/veos/core.* (存在する場合)
   /var/lib/systemd/coredump/core.veos.* (存在する場合)
   /var/lib/systemd/coredump/core.ived.* (存在する場合)
   /var/lib/systemd/coredump/core.vemmd.* (存在する場合)

  最後に、ログレベルを元に戻して、VEOSをリブートしてください。

   $ sudo cp /etc/opt/nec/ve/veos/log4crc.org /etc/opt/nec/ve/veos/log4crc
   $ sudo systemctl restart 've-os-launcher@*'
   $ unset LOG4C_RCPATH
